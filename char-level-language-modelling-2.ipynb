{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9568486,"sourceType":"datasetVersion","datasetId":5832038}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\ndevice = torch.device(\"cuda\")","metadata":{"execution":{"iopub.status.busy":"2024-10-09T14:03:50.937454Z","iopub.execute_input":"2024-10-09T14:03:50.937719Z","iopub.status.idle":"2024-10-09T14:03:54.234481Z","shell.execute_reply.started":"2024-10-09T14:03:50.937688Z","shell.execute_reply":"2024-10-09T14:03:54.233472Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/char-level-mode-text/shakespeare.txt') as f:\n    text = f.read()","metadata":{"execution":{"iopub.status.busy":"2024-10-09T14:03:54.236478Z","iopub.execute_input":"2024-10-09T14:03:54.236986Z","iopub.status.idle":"2024-10-09T14:03:54.332985Z","shell.execute_reply.started":"2024-10-09T14:03:54.236941Z","shell.execute_reply":"2024-10-09T14:03:54.332066Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"all_char = set(text)\nn_unique_char = len(all_char)","metadata":{"execution":{"iopub.status.busy":"2024-10-09T14:03:54.334567Z","iopub.execute_input":"2024-10-09T14:03:54.335183Z","iopub.status.idle":"2024-10-09T14:03:54.414506Z","shell.execute_reply.started":"2024-10-09T14:03:54.335138Z","shell.execute_reply":"2024-10-09T14:03:54.413486Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"decoder = dict(enumerate(all_char))\nencoder = {char:ind for ind,char in decoder.items()}","metadata":{"execution":{"iopub.status.busy":"2024-10-09T14:03:54.417401Z","iopub.execute_input":"2024-10-09T14:03:54.418185Z","iopub.status.idle":"2024-10-09T14:03:54.424351Z","shell.execute_reply.started":"2024-10-09T14:03:54.418145Z","shell.execute_reply":"2024-10-09T14:03:54.423518Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"encoded_text = np.array([encoder[char] for char in text])","metadata":{"execution":{"iopub.status.busy":"2024-10-09T14:03:54.425489Z","iopub.execute_input":"2024-10-09T14:03:54.425867Z","iopub.status.idle":"2024-10-09T14:03:55.446051Z","shell.execute_reply.started":"2024-10-09T14:03:54.425826Z","shell.execute_reply":"2024-10-09T14:03:55.445001Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def one_hot_encoder(encoded_text,n_unique_char):\n    one_hot = np.zeros((encoded_text.size,n_unique_char)).astype(np.float32)\n    one_hot[np.arange(one_hot.shape[0]),encoded_text.flatten()] = 1.0\n    one_hot = one_hot.reshape((*encoded_text.shape,n_unique_char))\n    return one_hot   ","metadata":{"execution":{"iopub.status.busy":"2024-10-09T14:03:55.447256Z","iopub.execute_input":"2024-10-09T14:03:55.447561Z","iopub.status.idle":"2024-10-09T14:03:55.453274Z","shell.execute_reply.started":"2024-10-09T14:03:55.447529Z","shell.execute_reply":"2024-10-09T14:03:55.452049Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def generate_batches(encoded_text,sample_per_batch=10,seq_len=50):\n    char_per_batch = sample_per_batch * seq_len\n    avail_batch = int(len(encoded_text)/char_per_batch)\n    encoded_text = encoded_text[:char_per_batch*avail_batch]\n    encoded_text = encoded_text.reshape((sample_per_batch,-1))\n    \n    for n in range(0,encoded_text.shape[1],seq_len):\n        x = encoded_text[:,n:n+seq_len]\n        y = np.zeros_like(x)\n        try : \n            y[:,:-1] = x[:,1:]\n            y[:,-1] = encoded_text[:,n+seq_len]\n        #for the very last case\n        except : \n            y[:,:-1] = x[:,1:]\n            y[:,-1] = encoded_text[:,0]\n        yield x,y","metadata":{"execution":{"iopub.status.busy":"2024-10-09T14:03:55.454408Z","iopub.execute_input":"2024-10-09T14:03:55.454714Z","iopub.status.idle":"2024-10-09T14:03:55.464846Z","shell.execute_reply.started":"2024-10-09T14:03:55.454684Z","shell.execute_reply":"2024-10-09T14:03:55.463875Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"batch_generator = generate_batches(encoded_text,sample_per_batch=10,seq_len=50)","metadata":{"execution":{"iopub.status.busy":"2024-10-09T14:03:55.465982Z","iopub.execute_input":"2024-10-09T14:03:55.466498Z","iopub.status.idle":"2024-10-09T14:03:55.474772Z","shell.execute_reply.started":"2024-10-09T14:03:55.466450Z","shell.execute_reply":"2024-10-09T14:03:55.473877Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"x,y = next(batch_generator)","metadata":{"execution":{"iopub.status.busy":"2024-10-09T14:03:55.475911Z","iopub.execute_input":"2024-10-09T14:03:55.476209Z","iopub.status.idle":"2024-10-09T14:03:55.485134Z","shell.execute_reply.started":"2024-10-09T14:03:55.476179Z","shell.execute_reply":"2024-10-09T14:03:55.484215Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class LSTM(nn.Module):\n    def __init__(self,all_char,num_hidden=512,num_layers=3,drop_prob=0.5):\n        super(LSTM,self).__init__()\n        self.all_char = all_char\n        self.num_hidden = num_hidden\n        self.num_layers = num_layers\n        self.drop_prob = drop_prob\n        \n        self.decoder = dict(enumerate(all_char))\n        self.encoder = {char:ind for ind,char in decoder.items()}\n        \n        self.lstm = nn.LSTM(len(self.all_char),num_hidden,num_layers,dropout = drop_prob,batch_first=True)\n        self.fc_linear = nn.Linear(num_hidden,len(self.all_char))\n        self.dropout = nn.Dropout(drop_prob)\n    def forward(self,x,hidden):\n        lstm_out, hidden = self.lstm(x,hidden)\n        drop_out = self.dropout(lstm_out)\n        drop_out = drop_out.contiguous().view(-1,self.num_hidden)\n        final_out = self.fc_linear(drop_out)\n        return final_out,hidden\n    def init_hidden(self,batch_size):\n        hidden = (torch.zeros(self.num_layers,batch_size,self.num_hidden).to(device),\n                 torch.zeros(self.num_layers,batch_size,self.num_hidden).to(device))\n        return hidden\n        ","metadata":{"execution":{"iopub.status.busy":"2024-10-09T14:03:55.486264Z","iopub.execute_input":"2024-10-09T14:03:55.486582Z","iopub.status.idle":"2024-10-09T14:03:55.496439Z","shell.execute_reply.started":"2024-10-09T14:03:55.486551Z","shell.execute_reply":"2024-10-09T14:03:55.495570Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model = LSTM(all_char,num_hidden=1024,num_layers=4,drop_prob=0.6).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-10-09T14:03:55.500260Z","iopub.execute_input":"2024-10-09T14:03:55.500946Z","iopub.status.idle":"2024-10-09T14:03:56.099823Z","shell.execute_reply.started":"2024-10-09T14:03:55.500899Z","shell.execute_reply":"2024-10-09T14:03:56.098828Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2024-10-09T14:03:56.101006Z","iopub.execute_input":"2024-10-09T14:03:56.101303Z","iopub.status.idle":"2024-10-09T14:03:56.108785Z","shell.execute_reply.started":"2024-10-09T14:03:56.101271Z","shell.execute_reply":"2024-10-09T14:03:56.107864Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"LSTM(\n  (lstm): LSTM(84, 1024, num_layers=4, batch_first=True, dropout=0.6)\n  (fc_linear): Linear(in_features=1024, out_features=84, bias=True)\n  (dropout): Dropout(p=0.6, inplace=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-10-09T14:03:56.109916Z","iopub.execute_input":"2024-10-09T14:03:56.110199Z","iopub.status.idle":"2024-10-09T14:03:57.164252Z","shell.execute_reply.started":"2024-10-09T14:03:56.110162Z","shell.execute_reply":"2024-10-09T14:03:57.162639Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_percent = 0.9\ntrain_ind = int(len(encoded_text) * (train_percent))\ntrain_data = encoded_text[:train_ind]\nval_data = encoded_text[train_ind:]","metadata":{"execution":{"iopub.status.busy":"2024-10-09T14:03:57.165463Z","iopub.execute_input":"2024-10-09T14:03:57.165982Z","iopub.status.idle":"2024-10-09T14:03:57.170677Z","shell.execute_reply.started":"2024-10-09T14:03:57.165932Z","shell.execute_reply":"2024-10-09T14:03:57.169758Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"num_epoch = 20\nbatch_size = 100\nseq_len = 100\ntracker = 0\nnum_char = max(encoded_text)+1","metadata":{"execution":{"iopub.status.busy":"2024-10-09T14:03:57.171936Z","iopub.execute_input":"2024-10-09T14:03:57.172301Z","iopub.status.idle":"2024-10-09T14:03:57.853736Z","shell.execute_reply.started":"2024-10-09T14:03:57.172245Z","shell.execute_reply":"2024-10-09T14:03:57.852671Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model.train()","metadata":{"execution":{"iopub.status.busy":"2024-10-09T14:03:57.854942Z","iopub.execute_input":"2024-10-09T14:03:57.855279Z","iopub.status.idle":"2024-10-09T14:03:57.864962Z","shell.execute_reply.started":"2024-10-09T14:03:57.855236Z","shell.execute_reply":"2024-10-09T14:03:57.864035Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"LSTM(\n  (lstm): LSTM(84, 1024, num_layers=4, batch_first=True, dropout=0.6)\n  (fc_linear): Linear(in_features=1024, out_features=84, bias=True)\n  (dropout): Dropout(p=0.6, inplace=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"model.train()\nfor epoch in range(num_epoch):\n    hidden = model.init_hidden(batch_size)\n    for x,y in generate_batches(train_data,batch_size,seq_len):\n        tracker +=1 \n        x = one_hot_encoder(x,num_char)\n        inputs = torch.tensor(x).to(device)\n        targets = torch.LongTensor(y).to(device)\n        hidden = tuple([state.data for state in hidden])\n        model.zero_grad()\n        lstm_out,hidden = model.forward(inputs,hidden)\n        loss = criterion(lstm_out,targets.view(batch_size*seq_len).long())\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(),max_norm=5)\n        optimizer.step()\n        if tracker % 50 == 0:\n            val_hidden = model.init_hidden(batch_size)\n            val_losses = []\n            model.eval()\n            for x,y in generate_batches(val_data,batch_size,seq_len):\n                x = one_hot_encoder(x,num_char)\n                inputs = torch.tensor(x).to(device)\n                targets = torch.LongTensor(y).to(device)\n                val_hidden = tuple([state.data for state in hidden])\n                lstm_output,val_hidden = model.forward(inputs,val_hidden)\n                val_loss = criterion(lstm_output,targets.view(batch_size*seq_len).long())\n                val_losses.append(val_loss.item())\n            model.train()\n            print(f\"epoch  : {epoch+1} step : {tracker} val_loss : {val_loss.item()}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-09T14:03:57.866418Z","iopub.execute_input":"2024-10-09T14:03:57.867130Z","iopub.status.idle":"2024-10-09T15:09:42.314785Z","shell.execute_reply.started":"2024-10-09T14:03:57.867085Z","shell.execute_reply":"2024-10-09T15:09:42.313792Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"epoch  : 1 step : 50 val_loss : 3.1927735805511475\nepoch  : 1 step : 100 val_loss : 3.0099895000457764\nepoch  : 1 step : 150 val_loss : 2.521446943283081\nepoch  : 1 step : 200 val_loss : 2.314289093017578\nepoch  : 1 step : 250 val_loss : 2.1889312267303467\nepoch  : 1 step : 300 val_loss : 2.1046571731567383\nepoch  : 1 step : 350 val_loss : 2.030832290649414\nepoch  : 1 step : 400 val_loss : 1.961775779724121\nepoch  : 1 step : 450 val_loss : 1.9127683639526367\nepoch  : 2 step : 500 val_loss : 1.8476203680038452\nepoch  : 2 step : 550 val_loss : 1.8103877305984497\nepoch  : 2 step : 600 val_loss : 1.7718286514282227\nepoch  : 2 step : 650 val_loss : 1.7311971187591553\nepoch  : 2 step : 700 val_loss : 1.7184250354766846\nepoch  : 2 step : 750 val_loss : 1.6885802745819092\nepoch  : 2 step : 800 val_loss : 1.6591687202453613\nepoch  : 2 step : 850 val_loss : 1.661063313484192\nepoch  : 2 step : 900 val_loss : 1.643154501914978\nepoch  : 2 step : 950 val_loss : 1.6288139820098877\nepoch  : 3 step : 1000 val_loss : 1.6163662672042847\nepoch  : 3 step : 1050 val_loss : 1.5987787246704102\nepoch  : 3 step : 1100 val_loss : 1.596833348274231\nepoch  : 3 step : 1150 val_loss : 1.5781562328338623\nepoch  : 3 step : 1200 val_loss : 1.585466742515564\nepoch  : 3 step : 1250 val_loss : 1.5737758874893188\nepoch  : 3 step : 1300 val_loss : 1.5677282810211182\nepoch  : 3 step : 1350 val_loss : 1.5531487464904785\nepoch  : 3 step : 1400 val_loss : 1.563525676727295\nepoch  : 3 step : 1450 val_loss : 1.5730177164077759\nepoch  : 4 step : 1500 val_loss : 1.5346314907073975\nepoch  : 4 step : 1550 val_loss : 1.540895700454712\nepoch  : 4 step : 1600 val_loss : 1.5404530763626099\nepoch  : 4 step : 1650 val_loss : 1.5532103776931763\nepoch  : 4 step : 1700 val_loss : 1.5289058685302734\nepoch  : 4 step : 1750 val_loss : 1.5271434783935547\nepoch  : 4 step : 1800 val_loss : 1.5303516387939453\nepoch  : 4 step : 1850 val_loss : 1.5412081480026245\nepoch  : 4 step : 1900 val_loss : 1.5264580249786377\nepoch  : 4 step : 1950 val_loss : 1.5250905752182007\nepoch  : 5 step : 2000 val_loss : 1.5088080167770386\nepoch  : 5 step : 2050 val_loss : 1.518721342086792\nepoch  : 5 step : 2100 val_loss : 1.5178232192993164\nepoch  : 5 step : 2150 val_loss : 1.5210541486740112\nepoch  : 5 step : 2200 val_loss : 1.529712438583374\nepoch  : 5 step : 2250 val_loss : 1.5249143838882446\nepoch  : 5 step : 2300 val_loss : 1.4922577142715454\nepoch  : 5 step : 2350 val_loss : 1.5190495252609253\nepoch  : 5 step : 2400 val_loss : 1.5252820253372192\nepoch  : 5 step : 2450 val_loss : 1.5136996507644653\nepoch  : 6 step : 2500 val_loss : 1.5004055500030518\nepoch  : 6 step : 2550 val_loss : 1.4976887702941895\nepoch  : 6 step : 2600 val_loss : 1.4811313152313232\nepoch  : 6 step : 2650 val_loss : 1.4985679388046265\nepoch  : 6 step : 2700 val_loss : 1.5048787593841553\nepoch  : 6 step : 2750 val_loss : 1.510632872581482\nepoch  : 6 step : 2800 val_loss : 1.5182141065597534\nepoch  : 6 step : 2850 val_loss : 1.5012761354446411\nepoch  : 6 step : 2900 val_loss : 1.5311230421066284\nepoch  : 7 step : 2950 val_loss : 1.4691660404205322\nepoch  : 7 step : 3000 val_loss : 1.5077091455459595\nepoch  : 7 step : 3050 val_loss : 1.512115478515625\nepoch  : 7 step : 3100 val_loss : 1.4883811473846436\nepoch  : 7 step : 3150 val_loss : 1.4905277490615845\nepoch  : 7 step : 3200 val_loss : 1.4921348094940186\nepoch  : 7 step : 3250 val_loss : 1.4964364767074585\nepoch  : 7 step : 3300 val_loss : 1.5034610033035278\nepoch  : 7 step : 3350 val_loss : 1.5168884992599487\nepoch  : 7 step : 3400 val_loss : 1.5002421140670776\nepoch  : 8 step : 3450 val_loss : 1.4989967346191406\nepoch  : 8 step : 3500 val_loss : 1.477671504020691\nepoch  : 8 step : 3550 val_loss : 1.495647668838501\nepoch  : 8 step : 3600 val_loss : 1.4770804643630981\nepoch  : 8 step : 3650 val_loss : 1.5096633434295654\nepoch  : 8 step : 3700 val_loss : 1.4930227994918823\nepoch  : 8 step : 3750 val_loss : 1.513933539390564\nepoch  : 8 step : 3800 val_loss : 1.509433388710022\nepoch  : 8 step : 3850 val_loss : 1.5002268552780151\nepoch  : 8 step : 3900 val_loss : 1.5293214321136475\nepoch  : 9 step : 3950 val_loss : 1.4754718542099\nepoch  : 9 step : 4000 val_loss : 1.494397759437561\nepoch  : 9 step : 4050 val_loss : 1.506530523300171\nepoch  : 9 step : 4100 val_loss : 1.503127098083496\nepoch  : 9 step : 4150 val_loss : 1.5050432682037354\nepoch  : 9 step : 4200 val_loss : 1.4979779720306396\nepoch  : 9 step : 4250 val_loss : 1.492681860923767\nepoch  : 9 step : 4300 val_loss : 1.5219337940216064\nepoch  : 9 step : 4350 val_loss : 1.496351957321167\nepoch  : 9 step : 4400 val_loss : 1.5032240152359009\nepoch  : 10 step : 4450 val_loss : 1.489950180053711\nepoch  : 10 step : 4500 val_loss : 1.4985536336898804\nepoch  : 10 step : 4550 val_loss : 1.5048377513885498\nepoch  : 10 step : 4600 val_loss : 1.487981915473938\nepoch  : 10 step : 4650 val_loss : 1.508487343788147\nepoch  : 10 step : 4700 val_loss : 1.5048139095306396\nepoch  : 10 step : 4750 val_loss : 1.4883897304534912\nepoch  : 10 step : 4800 val_loss : 1.5154751539230347\nepoch  : 10 step : 4850 val_loss : 1.5178290605545044\nepoch  : 10 step : 4900 val_loss : 1.4985042810440063\nepoch  : 11 step : 4950 val_loss : 1.5009865760803223\nepoch  : 11 step : 5000 val_loss : 1.4933195114135742\nepoch  : 11 step : 5050 val_loss : 1.4851610660552979\nepoch  : 11 step : 5100 val_loss : 1.5107049942016602\nepoch  : 11 step : 5150 val_loss : 1.5086183547973633\nepoch  : 11 step : 5200 val_loss : 1.5045157670974731\nepoch  : 11 step : 5250 val_loss : 1.5210663080215454\nepoch  : 11 step : 5300 val_loss : 1.4848544597625732\nepoch  : 11 step : 5350 val_loss : 1.5363160371780396\nepoch  : 12 step : 5400 val_loss : 1.4716153144836426\nepoch  : 12 step : 5450 val_loss : 1.5286331176757812\nepoch  : 12 step : 5500 val_loss : 1.5218253135681152\nepoch  : 12 step : 5550 val_loss : 1.5023123025894165\nepoch  : 12 step : 5600 val_loss : 1.516993761062622\nepoch  : 12 step : 5650 val_loss : 1.5321953296661377\nepoch  : 12 step : 5700 val_loss : 1.5184375047683716\nepoch  : 12 step : 5750 val_loss : 1.5194182395935059\nepoch  : 12 step : 5800 val_loss : 1.514816164970398\nepoch  : 12 step : 5850 val_loss : 1.5280085802078247\nepoch  : 13 step : 5900 val_loss : 1.5223362445831299\nepoch  : 13 step : 5950 val_loss : 1.5046427249908447\nepoch  : 13 step : 6000 val_loss : 1.5303986072540283\nepoch  : 13 step : 6050 val_loss : 1.4913976192474365\nepoch  : 13 step : 6100 val_loss : 1.5299086570739746\nepoch  : 13 step : 6150 val_loss : 1.5042072534561157\nepoch  : 13 step : 6200 val_loss : 1.5233652591705322\nepoch  : 13 step : 6250 val_loss : 1.5052452087402344\nepoch  : 13 step : 6300 val_loss : 1.5122885704040527\nepoch  : 13 step : 6350 val_loss : 1.544822335243225\nepoch  : 14 step : 6400 val_loss : 1.4903203248977661\nepoch  : 14 step : 6450 val_loss : 1.523712158203125\nepoch  : 14 step : 6500 val_loss : 1.512356162071228\nepoch  : 14 step : 6550 val_loss : 1.5242303609848022\nepoch  : 14 step : 6600 val_loss : 1.521878957748413\nepoch  : 14 step : 6650 val_loss : 1.5236705541610718\nepoch  : 14 step : 6700 val_loss : 1.5137369632720947\nepoch  : 14 step : 6750 val_loss : 1.552254557609558\nepoch  : 14 step : 6800 val_loss : 1.5330913066864014\nepoch  : 14 step : 6850 val_loss : 1.5252773761749268\nepoch  : 15 step : 6900 val_loss : 1.5062487125396729\nepoch  : 15 step : 6950 val_loss : 1.5182708501815796\nepoch  : 15 step : 7000 val_loss : 1.5173484086990356\nepoch  : 15 step : 7050 val_loss : 1.500592827796936\nepoch  : 15 step : 7100 val_loss : 1.5368057489395142\nepoch  : 15 step : 7150 val_loss : 1.527970790863037\nepoch  : 15 step : 7200 val_loss : 1.510604977607727\nepoch  : 15 step : 7250 val_loss : 1.5230435132980347\nepoch  : 15 step : 7300 val_loss : 1.556493878364563\nepoch  : 15 step : 7350 val_loss : 1.527633547782898\nepoch  : 16 step : 7400 val_loss : 1.529476284980774\nepoch  : 16 step : 7450 val_loss : 1.5132529735565186\nepoch  : 16 step : 7500 val_loss : 1.4992934465408325\nepoch  : 16 step : 7550 val_loss : 1.5243475437164307\nepoch  : 16 step : 7600 val_loss : 1.5340023040771484\nepoch  : 16 step : 7650 val_loss : 1.519331693649292\nepoch  : 16 step : 7700 val_loss : 1.5367685556411743\nepoch  : 16 step : 7750 val_loss : 1.501766562461853\nepoch  : 16 step : 7800 val_loss : 1.5550894737243652\nepoch  : 17 step : 7850 val_loss : 1.4869352579116821\nepoch  : 17 step : 7900 val_loss : 1.5551153421401978\nepoch  : 17 step : 7950 val_loss : 1.5442211627960205\nepoch  : 17 step : 8000 val_loss : 1.509507417678833\nepoch  : 17 step : 8050 val_loss : 1.526668906211853\nepoch  : 17 step : 8100 val_loss : 1.5332229137420654\nepoch  : 17 step : 8150 val_loss : 1.5393649339675903\nepoch  : 17 step : 8200 val_loss : 1.5384516716003418\nepoch  : 17 step : 8250 val_loss : 1.54444420337677\nepoch  : 17 step : 8300 val_loss : 1.5508899688720703\nepoch  : 18 step : 8350 val_loss : 1.5471879243850708\nepoch  : 18 step : 8400 val_loss : 1.5320653915405273\nepoch  : 18 step : 8450 val_loss : 1.554643988609314\nepoch  : 18 step : 8500 val_loss : 1.5297054052352905\nepoch  : 18 step : 8550 val_loss : 1.5358259677886963\nepoch  : 18 step : 8600 val_loss : 1.524577260017395\nepoch  : 18 step : 8650 val_loss : 1.560300588607788\nepoch  : 18 step : 8700 val_loss : 1.538924217224121\nepoch  : 18 step : 8750 val_loss : 1.5388197898864746\nepoch  : 18 step : 8800 val_loss : 1.5681627988815308\nepoch  : 19 step : 8850 val_loss : 1.5263984203338623\nepoch  : 19 step : 8900 val_loss : 1.5441107749938965\nepoch  : 19 step : 8950 val_loss : 1.5548382997512817\nepoch  : 19 step : 9000 val_loss : 1.5644898414611816\nepoch  : 19 step : 9050 val_loss : 1.551069974899292\nepoch  : 19 step : 9100 val_loss : 1.54397714138031\nepoch  : 19 step : 9150 val_loss : 1.5392274856567383\nepoch  : 19 step : 9200 val_loss : 1.57029128074646\nepoch  : 19 step : 9250 val_loss : 1.5552154779434204\nepoch  : 19 step : 9300 val_loss : 1.56617271900177\nepoch  : 20 step : 9350 val_loss : 1.5304476022720337\nepoch  : 20 step : 9400 val_loss : 1.5340423583984375\nepoch  : 20 step : 9450 val_loss : 1.5449274778366089\nepoch  : 20 step : 9500 val_loss : 1.5430771112442017\nepoch  : 20 step : 9550 val_loss : 1.5658537149429321\nepoch  : 20 step : 9600 val_loss : 1.5519887208938599\nepoch  : 20 step : 9650 val_loss : 1.5385559797286987\nepoch  : 20 step : 9700 val_loss : 1.5706136226654053\nepoch  : 20 step : 9750 val_loss : 1.5776705741882324\nepoch  : 20 step : 9800 val_loss : 1.5532171726226807\n","output_type":"stream"}]},{"cell_type":"code","source":"def pred_next_char(model,char,hidden=None,k=1):\n    encoded_text = model.encoder[char]\n    encoded_text = np.array([[encoded_text]]) \n    encoded_text = one_hot_encoder(encoded_text,len(model.all_char))\n    #create input by encoding and one_hotting the char\n    inputs = torch.tensor(encoded_text).to(device)\n    #create hidden state\n    hidden = tuple([state.data for state in hidden])\n    #make prediction\n    lstm_out,hidden = model.forward(inputs,hidden)\n    #get probabilities\n    probs = F.softmax(lstm_out,dim=1).data\n    probs = probs.cpu()\n    probs,index_position = probs.topk(k)\n    index_position = index_position.numpy().squeeze()\n    probs = probs.numpy().flatten()\n    probs = probs/probs.sum()\n    #choose a char from top k\n    char = np.random.choice(index_position,p=probs)\n    return model.decoder[char],hidden","metadata":{"execution":{"iopub.status.busy":"2024-10-09T15:09:42.316386Z","iopub.execute_input":"2024-10-09T15:09:42.317018Z","iopub.status.idle":"2024-10-09T15:09:42.325762Z","shell.execute_reply.started":"2024-10-09T15:09:42.316968Z","shell.execute_reply":"2024-10-09T15:09:42.324870Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def generate_text(model,size,seed = 'the',k=1):\n    model = model.to(device)\n    model.eval()\n    output_char = [c for c in seed]\n    hidden = model.init_hidden(1)\n    for char in seed:\n        char,hidden = pred_next_char(model,char,hidden,k=k)\n    output_char.append(char)\n    for i in range(size):\n        char,hidden = pred_next_char(model,output_char[-1],hidden,k=k)\n        output_char.append(char)\n    return ''.join(output_char)","metadata":{"execution":{"iopub.status.busy":"2024-10-09T15:09:42.327386Z","iopub.execute_input":"2024-10-09T15:09:42.328022Z","iopub.status.idle":"2024-10-09T15:09:42.337832Z","shell.execute_reply.started":"2024-10-09T15:09:42.327979Z","shell.execute_reply":"2024-10-09T15:09:42.336928Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"import torch.nn.functional as F\nprint(generate_text(model,2000,seed='The',k=2))","metadata":{"execution":{"iopub.status.busy":"2024-10-09T15:24:43.174178Z","iopub.execute_input":"2024-10-09T15:24:43.174894Z","iopub.status.idle":"2024-10-09T15:24:44.682125Z","shell.execute_reply.started":"2024-10-09T15:24:43.174854Z","shell.execute_reply":"2024-10-09T15:24:44.681114Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Theres' hearts,\n    To strike and see him there to think of them.\n    The star the field the sea and soul of heaven\n    Hath still success'd the senses of the world,\n    And that his state and thieves are the contraries\n    That stands and therefore shall be thought to see.\n    If thou dost see his soul that to the war\n    Was so their father's heart and sent thy son,\n    To see them to be true as he is born.\n    If thou hadst seen to stop their faces arm,\n    And, without triumph, the third the fiend of France,\n    The state, a soldier to the street of this\n    With their disposition that thou art a most,\n    Therefore the sea and three of them the sea,\n    And she will be a most right strain of him.\n    The stroke of this dear sister without son\n    Was to the sense of thine arms to th' state,\n    And that the sea and soul of this soldily\n    Will be the form and strange as the statues that have seen.\n    Therefore the world is to be thought to be\n    That the sun of him that hath seen the foot.\n    Therefore I say the sea, and the subject of them.\n    I have a soldier, and a man to thee.\n    The streets, the world to thee that thou art stronger,\n    And seek the foot of me and the strength that was\n    Than the common thought of the sea and sound\n    That stands the sea of his dear soul to sea.\n    The woman's father is the state of heaven.\n    The strength of this the streets, the world they hear\n    That stays and shall be so such a man of thine.\n    The sea of heaven will seem a most desire\n    To see this star that thou shalt seek a state.\n    I will not break this shame and this the world.\n    To the charms are to the world that's so sure to see,\n    And then to see the strong and start of me.\n    The world in such to stay the forest of the stroke,\n    The tricks of their discourses, the succession\n    With the strange traitors, that the streams of thee,\n    And therefore to my soul that shall be straight,\n    And to the sea of my displeasure shake\n    That they\n","output_type":"stream"}]}]}