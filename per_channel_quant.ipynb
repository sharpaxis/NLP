{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "224ef764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_channel_quant(tensor,dim,dtype):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0ba1125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "z = torch.randint(low=-150,high=150,size=(3,3)) + torch.randn((3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ab3f2305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_tensor(tensor,dtype=torch.int8):\n",
    "    r_max = tensor.max()\n",
    "    r_min = tensor.min()\n",
    "    tensor_dtype = tensor.dtype\n",
    "    q_max = torch.iinfo(dtype).max\n",
    "    q_min = torch.iinfo(dtype).min\n",
    "    #scale must be in higher precision\n",
    "    scale = torch.tensor((r_max-r_min)/(q_max-q_min),dtype=tensor_dtype)\n",
    "    zero = int(torch.round(q_min - (r_min/scale)))\n",
    "    if zero > q_max:\n",
    "        zero = q_max\n",
    "    if zero < q_min:\n",
    "        zero = q_min\n",
    "    q_tensor = tensor/scale + zero\n",
    "    rounded_tensor = torch.round(q_tensor)\n",
    "    rounded_tensor = rounded_tensor.clamp(q_min,q_max).to(dtype)\n",
    "    return rounded_tensor,scale,zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b0d54f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q  : \n",
      "tensor([-128,  -99,  127], dtype=torch.int8)\n",
      "zero : -6\n",
      "scale : 1.1037447452545166\n",
      "without upcasting q-z : \n",
      "tensor([-122,  -93, -123], dtype=torch.int8)\n",
      "with upcasting q-z : \n",
      "tensor([-122.,  -93.,  133.])\n",
      "q  : \n",
      "tensor([ 127, -128,  -23], dtype=torch.int8)\n",
      "zero : 122\n",
      "scale : 0.5962054133415222\n",
      "without upcasting q-z : \n",
      "tensor([  5,   6, 111], dtype=torch.int8)\n",
      "with upcasting q-z : \n",
      "tensor([   5., -250., -145.])\n",
      "q  : \n",
      "tensor([  27, -128,  127], dtype=torch.int8)\n",
      "zero : -92\n",
      "scale : 0.5932983756065369\n",
      "without upcasting q-z : \n",
      "tensor([119, -36, -37], dtype=torch.int8)\n",
      "with upcasting q-z : \n",
      "tensor([119., -36., 219.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xw/knd54pd91c7cw57n21dntvx80000gn/T/ipykernel_24228/2609975628.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  scale = torch.tensor((r_max-r_min)/(q_max-q_min),dtype=tensor_dtype)\n"
     ]
    }
   ],
   "source": [
    "#define output dim for axis 0or1\n",
    "dim=1\n",
    "q_max=127\n",
    "output_dim = z.shape[dim]\n",
    "#create \n",
    "qs,scales,zeros = [],[],[]\n",
    "#iter over output dim\n",
    "for index in range(output_dim):\n",
    "    sub_tensor = z.select(dim,index)\n",
    "    q_sub,scale,zero = quantize_tensor(sub_tensor,torch.int8)\n",
    "    qs.append(q_sub)\n",
    "    scales.append(scale)\n",
    "    zeros.append(zero)\n",
    "qs = torch.stack(qs,dim)\n",
    "qs\n",
    "de_qs = []\n",
    "for index in range(output_dim):\n",
    "    sub_tensor = qs.select(dim,index)\n",
    "    sub_scale = scales[index]\n",
    "    sub_zero = zeros[index]\n",
    "    de_qs.append(de_quantize(sub_tensor,sub_scale,sub_zero,torch.float32))\n",
    "de_qs = torch.stack(de_qs,dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee1a1041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([116.5177, 101.5764, -78.5647])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select takes dim and index\n",
    "z.select(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09fa0242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[111.3387, -15.4664, 116.5177],\n",
       "        [-12.3060,  26.3288, 101.5764],\n",
       "        [105.9068, -57.8360, -78.5647]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d3bf1d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def de_quantize(tensor,scale,zero,dtype=torch.float32):\n",
    "    deq_tensor = scale * (tensor.float() - zero)\n",
    "    return deq_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "869ecf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_channel_quant(tensor,dim,dtype=torch.int8):\n",
    "    output_dim = tensor.shape[dim]\n",
    "    qs,scales,zeros = [],[],[]\n",
    "    for index in range(output_dim):\n",
    "        sub_tensor = tensor.select(dim,index)\n",
    "        q,s,z = quantize_tensor(sub_tensor,dtype)\n",
    "        qs.append(q)\n",
    "        scales.append(s)\n",
    "        zeros.append(z)\n",
    "    qs = torch.stack(qs,dim)\n",
    "    return qs,scales,zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "97b05b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_channel_de_quant(tensor,scales,zeros,dim,dtype=torch.float32):\n",
    "    output_dim = tensor.shape[dim]\n",
    "    de_qs = []\n",
    "    for index in range(output_dim):\n",
    "        sub_tensor = tensor.select(dim,index)\n",
    "        de_q = de_quantize(sub_tensor,scales[index],zeros[index],dtype)\n",
    "        de_qs.append(de_q)\n",
    "    de_qs = torch.stack(de_qs,dim)\n",
    "    return de_qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b3f5728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "z = torch.randint(low=-150,high=150,size=(3,3)) + torch.randn((3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91ba157",
   "metadata": {},
   "source": [
    "### dim =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b8a2ca5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[116.2372, -16.7232, -35.4347],\n",
       "        [ 36.0951, -82.5614, 103.2559],\n",
       "        [  4.6823, -67.4668,  11.3159]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1f7c170f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xw/knd54pd91c7cw57n21dntvx80000gn/T/ipykernel_24228/2609975628.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  scale = torch.tensor((r_max-r_min)/(q_max-q_min),dtype=tensor_dtype)\n"
     ]
    }
   ],
   "source": [
    "dim_0 = 0\n",
    "q_z_0,scales_0,zeros_0 = per_channel_quant(z,dim_0,dtype=torch.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "324c68f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 127,  -96, -128],\n",
       "        [  35, -128,  127],\n",
       "        [ 105, -128,  127]], dtype=torch.int8)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_z_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0723841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "de_q_z_0 = per_channel_de_quant(q_z_0,scales_0,zeros_0,dim_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8122c5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[115.9844, -16.6542, -35.6875],\n",
       "        [ 36.4348, -82.3426, 103.4747],\n",
       "        [  4.6343, -67.3514,  11.4312]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_q_z_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0c377d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[116.2372, -16.7232, -35.4347],\n",
       "        [ 36.0951, -82.5614, 103.2559],\n",
       "        [  4.6823, -67.4668,  11.3159]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3617750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(abs(z-de_q_z_0),annot=True,titl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
