{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54e46c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import spacy\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7731007",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/aadityajoshi/Downloads/Combined Data.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52434984",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['statement']\n",
    "df['label'] = df['status']\n",
    "df.drop(['statement','status'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e949f981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 2598:\n",
      "Text: accord hc say bbl pre order number pretty problem â€ 1.71 million seller 1 1st album 7 comeback 7dreamie\n",
      "Label: 0\n",
      "\n",
      "Example 23792:\n",
      "Text: create small subreddit post feeling accomplishment safe place judge support way call r sorrowness interested.all love fellow sad people\n",
      "Label: 1\n",
      "\n",
      "Example 7365:\n",
      "Text: start promise suicide note therapist suffer mental health illness year diagnose 6 year ago hate genuinely hate med boost serotonin level store buy serotonin birthday june tell end thing year provide thing well 24 achieve significant unlike parent sibling close friend connection linkedin turn 24 recently hit hard graduate university 21 internship local bank big 4 firm consulting firm startup pay internship end summer 2020 secure time pay job unlike peer pretty successful corporate world i.e. getting promote move international office london uk t\n",
      "Label: 1\n",
      "\n",
      "Example 14210:\n",
      "Text: wish people stop try help able accept want help sound cheesy situation get mad want help want help counteractive appreciate look well look make till tomorrow interfere make thing bad have responsibility have help work push deeply well annoy listen help want pull boot accept remain loose want help stop try want help\n",
      "Label: 1\n",
      "\n",
      "Example 24984:\n",
      "Text: 1 step forward step want anymore\n",
      "Label: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def print_random_examples(df):\n",
    "    # Check if the required columns exist in the DataFrame\n",
    "    if 'text' not in df.columns or 'label' not in df.columns:\n",
    "        print(\"The DataFrame must contain 'text' and 'label' columns.\")\n",
    "        return\n",
    "    \n",
    "    # Sample 5 random rows from the DataFrame\n",
    "    examples = df[['text', 'label']].sample(5)\n",
    "    \n",
    "    # Iterate through the sampled examples and print them\n",
    "    for idx, row in examples.iterrows():\n",
    "        print(f\"Example {idx + 1}:\")\n",
    "        print(f\"Text: {row['text']}\")\n",
    "        print(f\"Label: {row['label']}\\n\")\n",
    "\n",
    "print_random_examples(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04cc8e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "blanks = []\n",
    "for i,txt,lb in df.itertuples():\n",
    "    if type(txt) == str:\n",
    "        if txt.isspace():\n",
    "            blanks.append(i)\n",
    "df.drop(blanks,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f28fad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['len'] = df['text'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e2c12a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x3293ab910>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(df['len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "344b0063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1109.0\n"
     ]
    }
   ],
   "source": [
    "print(df['len'].quantile(0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e60cabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_list = list(df[df['len'] >= 1000].index)\n",
    "for i in ind_list:\n",
    "    df['text'].loc[i] = df['text'].loc[i][:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c24a6b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('len',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f3b3486",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e4db00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean text\n",
    "def clean_lemm(text):\n",
    "    doc = nlp(text.lower())\n",
    "    clean_text = [token.lemma_ for token in doc if not token.is_punct and not token.is_stop]\n",
    "    return ' '.join(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad5566f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(clean_lemm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b89ca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label\n",
    "#normal - 0\n",
    "#other - 1\n",
    "bin_label = {'Normal':0,'Depression':1,'Suicidal':1,'Anxiety':1,'Bipolar':1,'Stress':1,'Personality disorder':1}\n",
    "df['label'] = df['label'].replace(bin_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35e3ee6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Normal                  16040\n",
       "Depression              15094\n",
       "Suicidal                10644\n",
       "Anxiety                  3623\n",
       "Bipolar                  2501\n",
       "Stress                   2296\n",
       "Personality disorder      895\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9515bc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_tokenizer(text):\n",
    "    clean_text = clean_lemm(text)\n",
    "    return clean_text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "92a922a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 3\n",
    "specials = ('<pad>','<unk>')\n",
    "token_count = defaultdict(int)\n",
    "for text in df['text']:\n",
    "    for token in spacy_tokenizer(text):\n",
    "        token_count[token] += 1\n",
    "vocab = {token:idx for idx,(token,count) in enumerate(token_count.items()) if count>= min_freq}\n",
    "for special in specials:\n",
    "    if special not in vocab:\n",
    "        vocab[special] = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a7a3baae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14810"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12147c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text and label pipeline\n",
    "text_pipeline = lambda x : [vocab.get(token,vocab['<unk>']) for token in spacy_tokenizer(x)]\n",
    "label_pipeline = lambda x : int(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "de557081",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self,df,text_pipeline,label_pipeline):\n",
    "        self.texts = df['text'].tolist()\n",
    "        self.labels = df['label'].tolist()\n",
    "        self.text_pipeline = text_pipeline\n",
    "        self.label_pipeline = label_pipeline\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    def __getitem__(self,idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        return self.text_pipeline(text),self.label_pipeline(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "24a93c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df,test_df = train_test_split(df,test_size=0.2,random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "39f88cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(train_df,text_pipeline,label_pipeline)\n",
    "test_dataset = TextDataset(test_df,text_pipeline,label_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1017332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate(batch):\n",
    "    text_list = []\n",
    "    label_list = []\n",
    "    for text,label in batch:\n",
    "        label_list.append(label)\n",
    "        text_list.append(torch.LongTensor(text))\n",
    "    label_list = torch.LongTensor(label_list)\n",
    "    text_list = pad_sequence(text_list,batch_first=True)\n",
    "    return text_list.to(device),label_list.to(device)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aff5eef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 64\n",
    "test_batch_size = 64\n",
    "train_loader = DataLoader(train_dataset,train_batch_size,shuffle=True,collate_fn = pad_collate)\n",
    "test_loader = DataLoader(test_dataset,test_batch_size,shuffle=False,collate_fn = pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "189372c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM\n",
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self,vocab_size,embedding_dim,hidden_size,out_size,num_layers,bidirectional,p=0.4):\n",
    "        super(LSTM,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_dir = 2 if bidirectional else 1\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.embedding = nn.Embedding(vocab_size,embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim,hidden_size,num_layers=num_layers,bidirectional=bidirectional,batch_first=True)\n",
    "        self.fc = nn.Linear(self.num_dir*hidden_size,out_size)\n",
    "    def forward(self,x):\n",
    "        hidden = self.init_hidden(x.size(0))\n",
    "        embeddings = self.embedding(x)\n",
    "        lstm_out,hidden = self.lstm(embeddings,hidden)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        pred = self.fc(lstm_out[:,-1,:])\n",
    "        return pred\n",
    "    def init_hidden(self,batch_size):\n",
    "        hidden = (torch.zeros(self.num_dir*self.num_layers,batch_size,self.hidden_size).to(device),\n",
    "                 torch.zeros(self.num_dir*self.num_layers,batch_size,self.hidden_size).to(device))\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f2d5d416",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM(vocab_size,embedding_dim=32,hidden_size=16,out_size=2,num_layers=2,bidirectional=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9332c9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       "  (embedding): Embedding(14810, 32)\n",
       "  (lstm): LSTM(32, 16, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=16, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8cb8824c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "optimizer = torch.optim.Adam(lstm.parameters(),lr=0.005)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d41e0b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|█████████████████| 639/639 [03:49<00:00,  2.78it/s, loss=0.1140]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Average Loss: 0.3336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|█████████████████| 639/639 [03:48<00:00,  2.80it/s, loss=0.1356]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Average Loss: 0.1665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|█████████████████| 639/639 [03:46<00:00,  2.82it/s, loss=0.1004]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Average Loss: 0.1332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|█████████████████| 639/639 [03:44<00:00,  2.85it/s, loss=0.1068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Average Loss: 0.1108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|█████████████████| 639/639 [03:45<00:00,  2.83it/s, loss=0.1592]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Average Loss: 0.0923\n",
      "Total training time: 18.90 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    lstm.train()\n",
    "    # Wrap your train_loader with tqdm\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    total_loss = 0\n",
    "    for text, label in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = lstm(text)\n",
    "        loss = criterion(y_pred, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update total loss and progress bar\n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    # Calculate and print average loss for the epoch\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(f\"Total training time: {(time.time() - start) / 60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "72810d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90      3235\n",
      "           1       0.95      0.96      0.95      6984\n",
      "\n",
      "    accuracy                           0.94     10219\n",
      "   macro avg       0.93      0.93      0.93     10219\n",
      "weighted avg       0.94      0.94      0.94     10219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "lstm.eval()\n",
    "with torch.no_grad():\n",
    "    for text, label in test_loader:\n",
    "        pred = lstm(text)\n",
    "        pred = torch.argmax(pred, dim=1)\n",
    "        \n",
    "        # Collect predictions and labels\n",
    "        all_preds.extend(pred.cpu().numpy())\n",
    "        all_labels.extend(label.cpu().numpy())\n",
    "\n",
    "# Now, use classification_report with the collected predictions and labels\n",
    "print(classification_report(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a6cad8",
   "metadata": {},
   "source": [
    "### BILSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "14903339",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BILSTM\n",
    "class BILSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self,vocab_size,embedding_dim,hidden_size,out_size,num_layers,bidirectional=True,p=0.4):\n",
    "        super(BILSTM,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_dir = 2 if bidirectional else 1\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.embedding = nn.Embedding(vocab_size,embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim,hidden_size,num_layers=num_layers,bidirectional=bidirectional,batch_first=True)\n",
    "        self.fc = nn.Linear(self.num_dir*hidden_size,out_size)\n",
    "    def forward(self,x):\n",
    "        hidden = self.init_hidden(x.size(0))\n",
    "        embeddings = self.embedding(x)\n",
    "        lstm_out,hidden = self.lstm(embeddings,hidden)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        pred = self.fc(lstm_out[:,-1,:])\n",
    "        return pred\n",
    "    def init_hidden(self,batch_size):\n",
    "        hidden = (torch.zeros(self.num_dir*self.num_layers,batch_size,self.hidden_size).to(device),\n",
    "                 torch.zeros(self.num_dir*self.num_layers,batch_size,self.hidden_size).to(device))\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dd707c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_lstm = BILSTM(vocab_size,embedding_dim=64,hidden_size=16,out_size=2,num_layers=2,bidirectional=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7eaeb4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|█████████████████| 639/639 [03:51<00:00,  2.76it/s, loss=0.1199]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Average Loss: 0.3298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|█████████████████| 639/639 [03:50<00:00,  2.77it/s, loss=0.0971]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Average Loss: 0.1646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|█████████████████| 639/639 [03:50<00:00,  2.77it/s, loss=0.0627]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Average Loss: 0.1272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|█████████████████| 639/639 [03:48<00:00,  2.79it/s, loss=0.0601]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Average Loss: 0.1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|█████████████████| 639/639 [03:49<00:00,  2.79it/s, loss=0.0898]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Average Loss: 0.0841\n",
      "Total training time: 19.18 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "optimizer = torch.optim.Adam(bi_lstm.parameters(),lr=0.005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    bi_lstm.train()\n",
    "    # Wrap your train_loader with tqdm\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    total_loss = 0\n",
    "    for text, label in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = bi_lstm(text)\n",
    "        loss = criterion(y_pred, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update total loss and progress bar\n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    # Calculate and print average loss for the epoch\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(f\"Total training time: {(time.time() - start) / 60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0b9b10db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90      3235\n",
      "           1       0.95      0.95      0.95      6984\n",
      "\n",
      "    accuracy                           0.94     10219\n",
      "   macro avg       0.93      0.93      0.93     10219\n",
      "weighted avg       0.94      0.94      0.94     10219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "bi_lstm.eval()\n",
    "with torch.no_grad():\n",
    "    for text, label in test_loader:\n",
    "        pred = bi_lstm(text)\n",
    "        pred = torch.argmax(pred, dim=1)\n",
    "        \n",
    "        # Collect predictions and labels\n",
    "        all_preds.extend(pred.cpu().numpy())\n",
    "        all_labels.extend(label.cpu().numpy())\n",
    "\n",
    "# Now, use classification_report with the collected predictions and labels\n",
    "print(classification_report(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee231c1",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "13931c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    \n",
    "    def __init__(self,vocab_size,embedding_dim,hidden_size,out_size,num_layers,bidirectional,p=0.4):\n",
    "        super(GRU,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_dir = 2 if bidirectional else 1\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.embedding = nn.Embedding(vocab_size,embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim,hidden_size,num_layers=num_layers,bidirectional=bidirectional,batch_first=True)\n",
    "        self.fc = nn.Linear(self.num_dir*hidden_size,out_size)\n",
    "    def forward(self,x):\n",
    "        hidden = self.init_hidden(x.size(0))\n",
    "        embeddings = self.embedding(x)\n",
    "        gru_out,hidden = self.gru(embeddings,hidden)\n",
    "        gru_out = self.dropout(gru_out)\n",
    "        pred = self.fc(gru_out[:,-1,:])\n",
    "        return pred\n",
    "    def init_hidden(self,batch_size):\n",
    "        hidden = (torch.zeros(self.num_dir*self.num_layers,batch_size,self.hidden_size).to(device))\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "32902e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = GRU(vocab_size,embedding_dim=64,hidden_size=16,out_size=2,num_layers=2,bidirectional=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d927a0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|█████████████████| 639/639 [04:47<00:00,  2.22it/s, loss=0.3129]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Average Loss: 0.2527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|█████████████████| 639/639 [04:47<00:00,  2.22it/s, loss=0.0811]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Average Loss: 0.1470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|█████████████████| 639/639 [04:47<00:00,  2.22it/s, loss=0.0282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Average Loss: 0.1123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|█████████████████| 639/639 [04:48<00:00,  2.21it/s, loss=0.3059]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Average Loss: 0.0899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|█████████████████| 639/639 [04:46<00:00,  2.23it/s, loss=0.0069]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Average Loss: 0.0706\n",
      "Total training time: 23.97 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "optimizer = torch.optim.Adam(gru.parameters(),lr=0.005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    gru.train()\n",
    "    # Wrap your train_loader with tqdm\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    total_loss = 0\n",
    "    for text, label in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = gru(text)\n",
    "        loss = criterion(y_pred, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update total loss and progress bar\n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    # Calculate and print average loss for the epoch\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(f\"Total training time: {(time.time() - start) / 60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "406e570c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90      3235\n",
      "           1       0.95      0.96      0.95      6984\n",
      "\n",
      "    accuracy                           0.94     10219\n",
      "   macro avg       0.93      0.92      0.93     10219\n",
      "weighted avg       0.94      0.94      0.94     10219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "gru.eval()\n",
    "with torch.no_grad():\n",
    "    for text, label in test_loader:\n",
    "        pred = gru(text)\n",
    "        pred = torch.argmax(pred, dim=1)\n",
    "        \n",
    "        # Collect predictions and labels\n",
    "        all_preds.extend(pred.cpu().numpy())\n",
    "        all_labels.extend(label.cpu().numpy())\n",
    "\n",
    "# Now, use classification_report with the collected predictions and labels\n",
    "print(classification_report(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e661d9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BIGRU(nn.Module):\n",
    "    \n",
    "    def __init__(self,vocab_size,embedding_dim,hidden_size,out_size,num_layers,bidirectional,p=0.4):\n",
    "        super(BIGRU,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_dir = 2 if bidirectional else 1\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.embedding = nn.Embedding(vocab_size,embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim,hidden_size,num_layers=num_layers,bidirectional=bidirectional,batch_first=True)\n",
    "        self.fc = nn.Linear(self.num_dir*hidden_size,out_size)\n",
    "    def forward(self,x):\n",
    "        hidden = self.init_hidden(x.size(0))\n",
    "        embeddings = self.embedding(x)\n",
    "        gru_out,hidden = self.gru(embeddings,hidden)\n",
    "        gru_out = self.dropout(gru_out)\n",
    "        pred = self.fc(gru_out[:,-1,:])\n",
    "        return pred\n",
    "    def init_hidden(self,batch_size):\n",
    "        hidden = (torch.zeros(self.num_dir*self.num_layers,batch_size,self.hidden_size).to(device))\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c52a8dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigru = BIGRU(vocab_size,embedding_dim=64,hidden_size=16,out_size=2,num_layers=2,bidirectional=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ec0fb1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|█████████████████| 639/639 [06:03<00:00,  1.76it/s, loss=0.1921]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Average Loss: 0.2419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|█████████████████| 639/639 [06:06<00:00,  1.74it/s, loss=0.2623]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Average Loss: 0.1418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|█████████████████| 639/639 [06:04<00:00,  1.75it/s, loss=0.0300]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Average Loss: 0.1044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|█████████████████| 639/639 [06:03<00:00,  1.76it/s, loss=0.1334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Average Loss: 0.0790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|█████████████████| 639/639 [06:04<00:00,  1.75it/s, loss=0.1285]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Average Loss: 0.0587\n",
      "Total training time: 30.38 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "optimizer = torch.optim.Adam(bigru.parameters(),lr=0.005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    bigru.train()\n",
    "    # Wrap your train_loader with tqdm\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    total_loss = 0\n",
    "    for text, label in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = bigru(text)\n",
    "        loss = criterion(y_pred, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update total loss and progress bar\n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    # Calculate and print average loss for the epoch\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(f\"Total training time: {(time.time() - start) / 60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "03db1753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.89      3235\n",
      "           1       0.95      0.95      0.95      6984\n",
      "\n",
      "    accuracy                           0.93     10219\n",
      "   macro avg       0.92      0.92      0.92     10219\n",
      "weighted avg       0.93      0.93      0.93     10219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "bigru.eval()\n",
    "with torch.no_grad():\n",
    "    for text, label in test_loader:\n",
    "        pred = bigru(text)\n",
    "        pred = torch.argmax(pred, dim=1)\n",
    "        \n",
    "        # Collect predictions and labels\n",
    "        all_preds.extend(pred.cpu().numpy())\n",
    "        all_labels.extend(label.cpu().numpy())\n",
    "\n",
    "# Now, use classification_report with the collected predictions and labels\n",
    "print(classification_report(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a485ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
