{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6897944,"sourceType":"datasetVersion","datasetId":3962399}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"#pipeline tokenizer->yield fn->vocab->text and label pipelines->dataset->collate fn->\n#->dataset and dataloader->LSTM->train and test","metadata":{},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#basic imports\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\nfrom sklearn.metrics import classification_report\nfrom collections import defaultdict","metadata":{},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\")","metadata":{},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/email-spam-classification-dataset/combined_data.csv')","metadata":{},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#ignore this part\nsampled_df = df.sample(frac=1)","metadata":{},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"sampled_df.info()","metadata":{},"execution_count":6,"outputs":[{"name":"stdout","output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\n\nIndex: 12517 entries, 35509 to 40206\n\nData columns (total 2 columns):\n\n #   Column  Non-Null Count  Dtype \n\n---  ------  --------------  ----- \n\n 0   label   12517 non-null  int64 \n\n 1   text    12517 non-null  object\n\ndtypes: int64(1), object(1)\n\nmemory usage: 293.4+ KB\n"}]},{"cell_type":"code","source":"sampled_df['len'] = sampled_df['text'].apply(len)\nsampled_df['len'].quantile(0.90)","metadata":{},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":["3379.399999999998"]},"metadata":{}}]},{"cell_type":"code","source":"sampled_df['label'].value_counts()","metadata":{},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":["label\n","1    6579\n","0    5938\n","Name: count, dtype: int64"]},"metadata":{}}]},{"cell_type":"code","source":"sampled_df.index = range(len(sampled_df))","metadata":{},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"sampled_df['len'] = sampled_df['text'].apply(len)\nsns.displot(sampled_df['len'])","metadata":{},"execution_count":10,"outputs":[{"name":"stderr","output_type":"stream","text":"/Users/aadityajoshi/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n\n  if pd.api.types.is_categorical_dtype(vector):\n\n/Users/aadityajoshi/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n\n  with pd.option_context('mode.use_inf_as_na', True):\n\n/Users/aadityajoshi/anaconda3/lib/python3.11/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight\n\n  self._figure.tight_layout(*args, **kwargs)\n"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":["<seaborn.axisgrid.FacetGrid at 0x34a0af110>"]},"metadata":{}},{"output_type":"display_data","data":{"image/png":"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","text/plain":["<Figure size 500x500 with 1 Axes>"]},"metadata":{}}]},{"cell_type":"code","source":"sampled_df = sampled_df[sampled_df['len'] <= 2500]","metadata":{},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"sampled_df.drop('len',axis=1,inplace=True)","metadata":{},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"sampled_df.info()","metadata":{},"execution_count":13,"outputs":[{"name":"stdout","output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\n\nIndex: 10517 entries, 0 to 12515\n\nData columns (total 2 columns):\n\n #   Column  Non-Null Count  Dtype \n\n---  ------  --------------  ----- \n\n 0   label   10517 non-null  int64 \n\n 1   text    10517 non-null  object\n\ndtypes: int64(1), object(1)\n\nmemory usage: 246.5+ KB\n"}]},{"cell_type":"code","source":"sampled_df.dropna(inplace=True)\nsampled_df.drop_duplicates(inplace=True)\nblanks = []\nfor i,txt,lb in sampled_df.itertuples():\n    if type(txt) == str:\n        if txt.isspace() == True:\n            blanks.append(i)\nblanks","metadata":{},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{}}]},{"cell_type":"code","source":"#clean text -> lemmatize \nimport spacy\nnlp = spacy.load('en_core_web_sm')","metadata":{},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#function for cleaning the text, first we lowercase the text\n#pass it into the spacy object\n#then we take lemmatization of text if its not stopword and a punctuation\ndef clean_lemm(text):\n    doc = nlp(text.lower())\n    clean_text = ' '.join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])\n    return clean_text","metadata":{},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"sampled_df['text'] = sampled_df['text'].apply(clean_lemm)","metadata":{},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"sampled_df['text'].head()","metadata":{},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":["0      revno escapenumber revision d tridge samba o...\n","1    dear code function call u glm u glm function x...\n","3    hi karina find email date site love sex loving...\n","4    ex student association university texas bring ...\n","5    national lottery \\n p o box 1010 \\n liverpool ...\n","Name: text, dtype: object"]},"metadata":{}}]},{"cell_type":"markdown","source":"#### get tokenizer and create vocab","metadata":{}},{"cell_type":"code","source":"def spacy_tokenizer(text):\n    # Use the clean_lemm function first\n    cleaned_text = clean_lemm(text)\n    # Then tokenize the cleaned text\n    return cleaned_text.split()","metadata":{},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def build_vocab(text_iterator, min_freq=3, specials=('<unk>', '<pad>')):\n    token_counts = defaultdict(int)\n    for text in text_iterator:\n        for token in spacy_tokenizer(text):\n            token_counts[token] += 1\n    vocab = {token: idx for idx, (token, count) in enumerate(token_counts.items()) if count >= min_freq}\n    for special in specials:\n        if special not in vocab:\n            vocab[special] = len(vocab) \n    return vocab","metadata":{},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"vocab = build_vocab(sampled_df['text'])","metadata":{},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"#### create vocab from iterator","metadata":{}},{"cell_type":"code","source":"vocab_size = len(vocab)\nvocab_size","metadata":{},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":["19669"]},"metadata":{}}]},{"cell_type":"markdown","source":"### text and label pipelines","metadata":{}},{"cell_type":"code","source":"text_pipeline = lambda text: [vocab.get(token, vocab['<unk>']) for token in spacy_tokenizer(text)]\nlabel_pipeline = lambda label: int(label)","metadata":{},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"#dataset\nclass EMAIL_Dataset(Dataset):\n    def __init__(self,email_df,text_pipeline,label_pipeline):\n        self.emails = email_df['text'].tolist()\n        self.labels = email_df['label'].tolist()\n        self.text_pipeline = text_pipeline\n        self.label_pipeline = label_pipeline\n    def __len__(self):\n        return len(self.emails)\n    def __getitem__(self,idx):\n        email = self.emails[idx]\n        label = self.labels[idx]\n        return self.text_pipeline(email),self.label_pipeline(label)\n    ","metadata":{},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_df,test_df = train_test_split(sampled_df,test_size=0.2)","metadata":{},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"train_data = EMAIL_Dataset(train_df,text_pipeline,label_pipeline)\ntest_data = EMAIL_Dataset(test_df,text_pipeline,label_pipeline)","metadata":{},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"### pad collate function","metadata":{}},{"cell_type":"code","source":"def pad_collate(batch):\n    text_list = []\n    label_list = []\n    for text,label in batch:\n        label_list.append(label)\n        text_list.append(torch.LongTensor(text))\n    label_list = torch.LongTensor(label_list)\n    text_list = pad_sequence(text_list,batch_first=True)\n    return text_list.to(device),label_list.to(device)","metadata":{},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"train_batch_size = 256\ntest_batch_size = 256\ntrain_loader = DataLoader(train_data,train_batch_size,shuffle=True,collate_fn=pad_collate)\ntest_loader = DataLoader(test_data,test_batch_size,shuffle=True,collate_fn=pad_collate)","metadata":{},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"### BILSTM","metadata":{}},{"cell_type":"code","source":"class LSTM(nn.Module):\n    #contructor method with parent call\n    def __init__(self,vocab_size,embedding_dim,hidden_size,out_size,num_layers,bidirectional,p=0.4):\n        #parent const call\n        super(LSTM,self).__init__()\n        self.num_layers = num_layers\n        self.hidden_size = hidden_size\n        self.num_dir = 2 if bidirectional else 1\n        #embedding\n        self.embedding = nn.Embedding(vocab_size,embedding_dim)\n        self.lstm = nn.LSTM(embedding_dim,hidden_size,num_layers=num_layers,bidirectional=bidirectional,batch_first=True)\n        self.fc = nn.Linear(self.num_dir*hidden_size,out_size)\n        self.dropout = nn.Dropout(p)\n    \n    def forward(self,x):\n        #prepare hidden and embedding\n        hidden = model.init_hidden(x.size(0))\n        embedding = self.embedding(x)\n        lstm_out,hidden = self.lstm(embedding,hidden)\n        lstm_out = self.dropout(lstm_out)\n        pred = self.fc(lstm_out[:,-1,:])\n        return pred\n    \n    def init_hidden(self,batch_size):\n        hidden = (torch.zeros(self.num_dir*self.num_layers,batch_size,self.hidden_size).to(device),\n                 torch.zeros(self.num_dir*self.num_layers,batch_size,self.hidden_size).to(device))\n        return hidden","metadata":{},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"model = LSTM(vocab_size,\n             embedding_dim=32,hidden_size=16,\n             out_size=2,num_layers=2,\n             bidirectional=True).to(device)","metadata":{},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"model","metadata":{},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":["LSTM(\n","  (embedding): Embedding(19669, 32)\n","  (lstm): LSTM(32, 16, num_layers=2, batch_first=True, bidirectional=True)\n","  (fc): Linear(in_features=32, out_features=2, bias=True)\n","  (dropout): Dropout(p=0.4, inplace=False)\n",")"]},"metadata":{}}]},{"cell_type":"code","source":"num_epochs = 5\noptimizer = torch.optim.Adam(model.parameters(),lr=0.005)\ncriterion = nn.CrossEntropyLoss()","metadata":{},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"import time\nstart = time.time()\nfor epoch in range(num_epochs):\n    model.train()\n    for text,label in train_loader:\n        optimizer.zero_grad()\n        y_pred = model.forward(text)\n        loss = criterion(y_pred,label)\n        loss.backward()\n        optimizer.step()\n    print(f\"epoch : {epoch+1} loss : {loss.item()}\")    \nprint((time.time()-start)/60)","metadata":{},"execution_count":36,"outputs":[{"name":"stdout","output_type":"stream","text":"epoch : 1 loss : 0.6237562894821167\n\nepoch : 2 loss : 0.0022558753844350576\n\nepoch : 3 loss : 0.6120662093162537\n\nepoch : 4 loss : 0.007311695721000433\n\nepoch : 5 loss : 0.009533943608403206\n\n11.183624017238618\n"}]},{"cell_type":"code","source":"all_preds = []\nall_labels = []\n\nmodel.eval()\nwith torch.no_grad():\n    for text, label in test_loader:\n        pred = model(text)\n        pred = torch.argmax(pred, dim=1)\n        \n        # Collect predictions and labels\n        all_preds.extend(pred.cpu().numpy())\n        all_labels.extend(label.cpu().numpy())\n\n# Now, use classification_report with the collected predictions and labels\nprint(classification_report(all_labels, all_preds))","metadata":{},"execution_count":37,"outputs":[{"name":"stdout","output_type":"stream","text":"              precision    recall  f1-score   support\n\n\n\n           0       0.97      0.96      0.96       978\n\n           1       0.96      0.97      0.97      1126\n\n\n\n    accuracy                           0.97      2104\n\n   macro avg       0.97      0.97      0.97      2104\n\nweighted avg       0.97      0.97      0.97      2104\n\n\n"}]},{"cell_type":"markdown","source":"### GRU","metadata":{}},{"cell_type":"code","source":"class GRU(nn.Module):\n    def __init__(self,vocab_size,embedding_dim,hidden_size,out_size,num_layers,bidirectional,p=0.4):\n        super(GRU,self).__init__()\n        \n        self.num_layers = num_layers\n        self.hidden_size = hidden_size\n        self.num_dir = 2 if bidirectional else 1\n        \n        self.embedding = nn.Embedding(vocab_size,embedding_dim)\n        \n        self.gru = nn.GRU(embedding_dim,hidden_size,num_layers=num_layers,bidirectional=bidirectional,batch_first=True)\n        self.fc = nn.Linear(self.num_dir * hidden_size,out_size)\n        \n        self.dropout = nn.Dropout()\n    \n    def forward(self, x):\n        embedding = self.embedding(x)\n        hidden = self.init_hidden(x.size(0))\n        gru_out, hidden = self.gru(embedding, hidden)\n        gru_out = self.dropout(gru_out)  # Apply dropout\n        pred = self.fc(gru_out[:, -1, :])\n        return pred\n\n    def init_hidden(self,batch_size):\n        hidden = (torch.zeros(self.num_dir*self.num_layers,batch_size,self.hidden_size)).to(device)\n        return hidden","metadata":{},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"GRU_model = GRU(vocab_size,embedding_dim=64,hidden_size=16,out_size=2,num_layers=2,bidirectional=True).to(device)","metadata":{},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"num_epochs = 5\noptimizer = torch.optim.Adam(GRU_model.parameters(),lr=0.005)\ncriterion = nn.CrossEntropyLoss()","metadata":{},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"import time\nfrom tqdm import tqdm\n\nstart = time.time()\nfor epoch in range(num_epochs):\n    GRU_model.train()\n    # Wrap your train_loader with tqdm\n    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n    total_loss = 0\n    for text, label in pbar:\n        optimizer.zero_grad()\n        y_pred = GRU_model(text)\n        loss = criterion(y_pred, label)\n        loss.backward()\n        optimizer.step()\n        \n        # Update total loss and progress bar\n        total_loss += loss.item()\n        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n    \n    # Calculate and print average loss for the epoch\n    avg_loss = total_loss / len(train_loader)\n    print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n\nprint(f\"Total training time: {(time.time() - start) / 60:.2f} minutes\")","metadata":{},"execution_count":50,"outputs":[{"name":"stderr","output_type":"stream","text":"Epoch 1/5: 100%|█████████████████| 263/263 [05:04<00:00,  1.16s/it, loss=0.1014]\n"},{"name":"stdout","output_type":"stream","text":"Epoch 1/5, Average Loss: 0.1349\n"},{"name":"stderr","output_type":"stream","text":"Epoch 2/5: 100%|█████████████████| 263/263 [05:00<00:00,  1.14s/it, loss=0.1197]\n"},{"name":"stdout","output_type":"stream","text":"Epoch 2/5, Average Loss: 0.0548\n"},{"name":"stderr","output_type":"stream","text":"Epoch 3/5: 100%|█████████████████| 263/263 [04:59<00:00,  1.14s/it, loss=0.0137]\n"},{"name":"stdout","output_type":"stream","text":"Epoch 3/5, Average Loss: 0.0274\n"},{"name":"stderr","output_type":"stream","text":"Epoch 4/5: 100%|█████████████████| 263/263 [05:06<00:00,  1.17s/it, loss=0.0009]\n"},{"name":"stdout","output_type":"stream","text":"Epoch 4/5, Average Loss: 0.0167\n"},{"name":"stderr","output_type":"stream","text":"Epoch 5/5: 100%|█████████████████| 263/263 [05:00<00:00,  1.14s/it, loss=0.0012]"},{"name":"stdout","output_type":"stream","text":"Epoch 5/5, Average Loss: 0.0173\n\nTotal training time: 25.20 minutes\n"},{"name":"stderr","output_type":"stream","text":"\n"}]},{"cell_type":"code","source":"all_preds = []\nall_labels = []\n\nGRU_model.eval()\nwith torch.no_grad():\n    for text, label in test_loader:\n        pred = GRU_model(text)\n        pred = torch.argmax(pred, dim=1)\n        \n        # Collect predictions and labels\n        all_preds.extend(pred.cpu().numpy())\n        all_labels.extend(label.cpu().numpy())\n\n# Now, use classification_report with the collected predictions and labels\nprint(classification_report(all_labels, all_preds))","metadata":{},"execution_count":51,"outputs":[{"name":"stdout","output_type":"stream","text":"              precision    recall  f1-score   support\n\n\n\n           0       0.95      0.96      0.95       978\n\n           1       0.96      0.96      0.96      1126\n\n\n\n    accuracy                           0.96      2104\n\n   macro avg       0.96      0.96      0.96      2104\n\nweighted avg       0.96      0.96      0.96      2104\n\n\n"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}