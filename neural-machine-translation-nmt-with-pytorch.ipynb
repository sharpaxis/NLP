{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"#!python -m spacy download de_core_news_sm\n#!pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchtext==0.15.2 -f https://download.pytorch.org/whl/torch_stable.html\n    ","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:18:25.370367Z","iopub.execute_input":"2024-10-29T13:18:25.370736Z","iopub.status.idle":"2024-10-29T13:18:25.376938Z","shell.execute_reply.started":"2024-10-29T13:18:25.370695Z","shell.execute_reply":"2024-10-29T13:18:25.375930Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#basic imports\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader,Dataset\nimport tqdm,datasets\nfrom torchtext.vocab import build_vocab_from_iterator\nfrom torch.nn.utils.rnn import pad_sequence","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:18:25.378662Z","iopub.execute_input":"2024-10-29T13:18:25.378986Z","iopub.status.idle":"2024-10-29T13:18:28.420192Z","shell.execute_reply.started":"2024-10-29T13:18:25.378954Z","shell.execute_reply":"2024-10-29T13:18:28.419411Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"dataset = datasets.load_dataset('bentrevett/multi30k')\ntrain_data,val_data,test_data = dataset['train'],dataset['validation'],dataset['test']","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:18:28.421382Z","iopub.execute_input":"2024-10-29T13:18:28.421965Z","iopub.status.idle":"2024-10-29T13:18:29.378167Z","shell.execute_reply.started":"2024-10-29T13:18:28.421919Z","shell.execute_reply":"2024-10-29T13:18:29.377373Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import torch\nprint(torch.cuda.is_available())  # Should return True\nprint(torch.cuda.get_device_name(0))  # Should print the GPU name","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:18:29.380510Z","iopub.execute_input":"2024-10-29T13:18:29.381164Z","iopub.status.idle":"2024-10-29T13:18:29.463495Z","shell.execute_reply.started":"2024-10-29T13:18:29.381119Z","shell.execute_reply":"2024-10-29T13:18:29.462617Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"True\nTesla T4\n","output_type":"stream"}]},{"cell_type":"code","source":"#load both models\n\nimport spacy\nen_nlp = spacy.load('en_core_web_sm')\nde_nlp = spacy.load('de_core_news_sm')","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:18:29.464541Z","iopub.execute_input":"2024-10-29T13:18:29.464816Z","iopub.status.idle":"2024-10-29T13:18:33.902669Z","shell.execute_reply.started":"2024-10-29T13:18:29.464785Z","shell.execute_reply":"2024-10-29T13:18:33.901826Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#tokenizer\ndef sample_tokenizer(sample,en_nlp,de_nlp,lower,max_length,sos_token,eos_token):\n    en_tokens = [token.text for token in en_nlp.tokenizer(sample[\"en\"])][:max_length]\n    de_tokens = [token.text for token in de_nlp.tokenizer(sample[\"de\"])][:max_length]\n    if lower == True:\n        en_tokens = [token.lower() for token in en_tokens]\n        de_tokens = [token.lower() for token in de_tokens]\n    en_tokens = [sos_token] + en_tokens + [eos_token]\n    de_tokens = [sos_token] + de_tokens + [eos_token]\n    return {\"en_tokens\":en_tokens,\"de_tokens\":de_tokens}","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:18:33.904115Z","iopub.execute_input":"2024-10-29T13:18:33.904613Z","iopub.status.idle":"2024-10-29T13:18:33.911052Z","shell.execute_reply.started":"2024-10-29T13:18:33.904578Z","shell.execute_reply":"2024-10-29T13:18:33.910119Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"fn_kwargs = {\n    \"en_nlp\":en_nlp,\n    \"de_nlp\":de_nlp,\n    \"lower\":True,\n    \"max_length\":1000,\n    \"sos_token\":'<sos>',\n    \"eos_token\":'<eos>'\n}\ntrain_data = train_data.map(sample_tokenizer,fn_kwargs=fn_kwargs)\nval_data = val_data.map(sample_tokenizer,fn_kwargs=fn_kwargs)\ntest_data = test_data.map(sample_tokenizer,fn_kwargs=fn_kwargs)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:18:33.912587Z","iopub.execute_input":"2024-10-29T13:18:33.912949Z","iopub.status.idle":"2024-10-29T13:18:46.132752Z","shell.execute_reply.started":"2024-10-29T13:18:33.912909Z","shell.execute_reply":"2024-10-29T13:18:46.131851Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/29000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"351d75a9edd8498cbdb34036b2ffb89c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1014 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e4cd1ef53bc4bcb9a87643fa51c3e7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2af182557b31480f8fe2048797dbf3a9"}},"metadata":{}}]},{"cell_type":"code","source":"#vocab\nmin_freq = 2\nspecials = ['<unk>','<pad>','<sos>','<eos>']\nen_vocab = build_vocab_from_iterator(train_data['en_tokens'],specials=specials,min_freq=min_freq)\nde_vocab = build_vocab_from_iterator(train_data['de_tokens'],specials=specials,min_freq=min_freq)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:18:46.133842Z","iopub.execute_input":"2024-10-29T13:18:46.134175Z","iopub.status.idle":"2024-10-29T13:18:47.869210Z","shell.execute_reply.started":"2024-10-29T13:18:46.134141Z","shell.execute_reply":"2024-10-29T13:18:47.868341Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"assert en_vocab['<unk>'] == de_vocab['<unk>']\nassert en_vocab['<pad>'] == de_vocab['<pad>']","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:18:47.870331Z","iopub.execute_input":"2024-10-29T13:18:47.870636Z","iopub.status.idle":"2024-10-29T13:18:47.875138Z","shell.execute_reply.started":"2024-10-29T13:18:47.870604Z","shell.execute_reply":"2024-10-29T13:18:47.874246Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"unk_index = en_vocab['<unk>']\npad_index = en_vocab['<pad>']\nen_vocab.set_default_index(unk_index)\nde_vocab.set_default_index(unk_index)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:18:47.878840Z","iopub.execute_input":"2024-10-29T13:18:47.879165Z","iopub.status.idle":"2024-10-29T13:18:47.894399Z","shell.execute_reply.started":"2024-10-29T13:18:47.879132Z","shell.execute_reply":"2024-10-29T13:18:47.893566Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#numericalize\ndef sample_num(sample,en_vocab,de_vocab):\n    en_ids = en_vocab.lookup_indices(sample[\"en_tokens\"])\n    de_ids = de_vocab.lookup_indices(sample[\"de_tokens\"])\n    return {\"en_ids\":en_ids,\"de_ids\":de_ids}","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:18:47.895463Z","iopub.execute_input":"2024-10-29T13:18:47.895744Z","iopub.status.idle":"2024-10-29T13:18:47.903046Z","shell.execute_reply.started":"2024-10-29T13:18:47.895713Z","shell.execute_reply":"2024-10-29T13:18:47.902287Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"fn_kwargs = {\"en_vocab\":en_vocab,\"de_vocab\":de_vocab}\ntrain_data = train_data.map(sample_num,fn_kwargs=fn_kwargs)\nval_data = val_data.map(sample_num,fn_kwargs=fn_kwargs)\ntest_data = test_data.map(sample_num,fn_kwargs=fn_kwargs)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:18:47.903987Z","iopub.execute_input":"2024-10-29T13:18:47.904247Z","iopub.status.idle":"2024-10-29T13:18:52.853029Z","shell.execute_reply.started":"2024-10-29T13:18:47.904218Z","shell.execute_reply":"2024-10-29T13:18:52.852164Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/29000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eea53597f03a4d1bbfe3d6c055d6fed1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1014 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d38856ad68584b119b47c9272b67ab82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"046db7d33fa545a88d75eacbb5d0a07c"}},"metadata":{}}]},{"cell_type":"code","source":"train_data[0]","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:18:52.854308Z","iopub.execute_input":"2024-10-29T13:18:52.854613Z","iopub.status.idle":"2024-10-29T13:18:52.863066Z","shell.execute_reply.started":"2024-10-29T13:18:52.854581Z","shell.execute_reply":"2024-10-29T13:18:52.862174Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"{'en': 'Two young, White males are outside near many bushes.',\n 'de': 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.',\n 'en_tokens': ['<sos>',\n  'two',\n  'young',\n  ',',\n  'white',\n  'males',\n  'are',\n  'outside',\n  'near',\n  'many',\n  'bushes',\n  '.',\n  '<eos>'],\n 'de_tokens': ['<sos>',\n  'zwei',\n  'junge',\n  'weiße',\n  'männer',\n  'sind',\n  'im',\n  'freien',\n  'in',\n  'der',\n  'nähe',\n  'vieler',\n  'büsche',\n  '.',\n  '<eos>'],\n 'en_ids': [2, 16, 24, 15, 25, 778, 17, 57, 80, 202, 1312, 5, 3],\n 'de_ids': [2, 18, 26, 253, 30, 84, 20, 88, 7, 15, 110, 7647, 3171, 4, 3]}"},"metadata":{}}]},{"cell_type":"code","source":"#format\ntrain_data = train_data.with_format(type=\"torch\",columns=['en_ids','de_ids'],output_all_columns=True)\nval_data = val_data.with_format(type=\"torch\",columns=['en_ids','de_ids'],output_all_columns=True)\ntest_data = test_data.with_format(type=\"torch\",columns=['en_ids','de_ids'],output_all_columns=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:18:52.864236Z","iopub.execute_input":"2024-10-29T13:18:52.864517Z","iopub.status.idle":"2024-10-29T13:18:52.970220Z","shell.execute_reply.started":"2024-10-29T13:18:52.864480Z","shell.execute_reply":"2024-10-29T13:18:52.969317Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_data[0]","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:18:52.971346Z","iopub.execute_input":"2024-10-29T13:18:52.971716Z","iopub.status.idle":"2024-10-29T13:18:52.984598Z","shell.execute_reply.started":"2024-10-29T13:18:52.971673Z","shell.execute_reply":"2024-10-29T13:18:52.983835Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{'en_ids': tensor([   2,   16,   24,   15,   25,  778,   17,   57,   80,  202, 1312,    5,\n            3]),\n 'de_ids': tensor([   2,   18,   26,  253,   30,   84,   20,   88,    7,   15,  110, 7647,\n         3171,    4,    3]),\n 'en': 'Two young, White males are outside near many bushes.',\n 'de': 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.',\n 'en_tokens': ['<sos>',\n  'two',\n  'young',\n  ',',\n  'white',\n  'males',\n  'are',\n  'outside',\n  'near',\n  'many',\n  'bushes',\n  '.',\n  '<eos>'],\n 'de_tokens': ['<sos>',\n  'zwei',\n  'junge',\n  'weiße',\n  'männer',\n  'sind',\n  'im',\n  'freien',\n  'in',\n  'der',\n  'nähe',\n  'vieler',\n  'büsche',\n  '.',\n  '<eos>']}"},"metadata":{}}]},{"cell_type":"code","source":"#collate funcction\ndef get_collate_fn(pad_index):\n    def collate_fn(batch):\n        batch_en_ids = [sample[\"en_ids\"] for sample in batch]\n        batch_de_ids = [sample[\"de_ids\"] for sample in batch]\n        batch_en_ids = pad_sequence(batch_en_ids,padding_value=pad_index)\n        batch_de_ids = pad_sequence(batch_de_ids,padding_value=pad_index)\n        batch = {\"en_ids\":batch_en_ids,\"de_ids\":batch_de_ids}\n        return batch\n    return collate_fn","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:18:52.985522Z","iopub.execute_input":"2024-10-29T13:18:52.985780Z","iopub.status.idle":"2024-10-29T13:18:52.991619Z","shell.execute_reply.started":"2024-10-29T13:18:52.985751Z","shell.execute_reply":"2024-10-29T13:18:52.990639Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def get_dataloader(dataset,batch_size,shuffle,pad_index):\n    collate_fn = get_collate_fn(pad_index)\n    dataloader = DataLoader(dataset=dataset,\n                            batch_size=batch_size,\n                            shuffle=shuffle,\n                           collate_fn=collate_fn)\n    return dataloader","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:18:52.992743Z","iopub.execute_input":"2024-10-29T13:18:52.993117Z","iopub.status.idle":"2024-10-29T13:18:52.998684Z","shell.execute_reply.started":"2024-10-29T13:18:52.993079Z","shell.execute_reply":"2024-10-29T13:18:52.997800Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_loader = get_dataloader(train_data,batch_size=512,shuffle=True,pad_index=pad_index)\nval_loader = get_dataloader(val_data,batch_size=512,shuffle=True,pad_index=pad_index)\ntest_loader = get_dataloader(test_data,batch_size=512,shuffle=True,pad_index=pad_index)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:18:52.999896Z","iopub.execute_input":"2024-10-29T13:18:53.000239Z","iopub.status.idle":"2024-10-29T13:18:53.008588Z","shell.execute_reply.started":"2024-10-29T13:18:53.000203Z","shell.execute_reply":"2024-10-29T13:18:53.007500Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"for x,y in train_loader:\n    break","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:18:53.010093Z","iopub.execute_input":"2024-10-29T13:18:53.010614Z","iopub.status.idle":"2024-10-29T13:18:53.122552Z","shell.execute_reply.started":"2024-10-29T13:18:53.010514Z","shell.execute_reply":"2024-10-29T13:18:53.121574Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:18:53.123734Z","iopub.execute_input":"2024-10-29T13:18:53.124053Z","iopub.status.idle":"2024-10-29T13:18:53.134432Z","shell.execute_reply.started":"2024-10-29T13:18:53.124020Z","shell.execute_reply":"2024-10-29T13:18:53.133447Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"'de_ids'"},"metadata":{}}]},{"cell_type":"markdown","source":"### Seq2seq model","metadata":{}},{"cell_type":"markdown","source":"#### 1.Encoder - > takes input and makes hidden and cell state","metadata":{}},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self,input_dim,embedding_dim,hidden_size,num_layers,dropout):\n        super(Encoder,self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.dropout = nn.Dropout(dropout)\n        self.embedding = nn.Embedding(input_dim,embedding_dim)\n        self.lstm = nn.LSTM(embedding_dim,hidden_size,num_layers=num_layers,bidirectional=True,dropout=dropout)\n    def forward(self,src):\n        embedded = self.dropout(self.embedding(src))\n        out,(hidden,cell) = self.lstm(embedded)\n        return hidden,cell","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:18:53.135535Z","iopub.execute_input":"2024-10-29T13:18:53.135911Z","iopub.status.idle":"2024-10-29T13:18:53.144257Z","shell.execute_reply.started":"2024-10-29T13:18:53.135855Z","shell.execute_reply":"2024-10-29T13:18:53.143274Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"#### 2.Decoder -> takes in output_dim(one hot vector over en_vocab) and outputs output_dim(softmax over en_vocab","metadata":{}},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self,output_dim,embedding_dim,hidden_size,num_layers,dropout):\n        super(Decoder,self).__init__()\n        self.output_dim = output_dim\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.dropout = nn.Dropout(dropout)\n        self.embedding = nn.Embedding(output_dim,embedding_dim)\n        self.lstm = nn.LSTM(embedding_dim,hidden_size,num_layers=num_layers,bidirectional=True,dropout=dropout)\n        self.fc = nn.Linear(hidden_size*2,output_dim)\n    def forward(self,input_token,hidden,cell):\n        input_token = input_token.unsqueeze(0)\n        emb = self.embedding(input_token)\n        emb = self.dropout(emb)\n        out,(hidden,cell) = self.lstm(emb,(hidden,cell))\n        out = out.squeeze(0)\n        pred = self.fc(out)\n        return pred,hidden,cell","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:18:53.145455Z","iopub.execute_input":"2024-10-29T13:18:53.145783Z","iopub.status.idle":"2024-10-29T13:18:53.155144Z","shell.execute_reply.started":"2024-10-29T13:18:53.145736Z","shell.execute_reply":"2024-10-29T13:18:53.154224Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## SEQ2SEQ","metadata":{}},{"cell_type":"code","source":"class Seq2Seq(nn.Module):\n    def __init__(self,encoder,decoder,device):\n        super(Seq2Seq,self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        assert encoder.num_layers == decoder.num_layers\n        assert encoder.hidden_size == decoder.hidden_size\n    def forward(self,src,trg,teacher_forcing_ratio):\n        #exctract dim for out vector\n        trg_len = trg.shape[0]\n        batch_size = trg.shape[1]\n        vocab_size = self.decoder.output_dim\n        outputs = torch.zeros(trg_len,batch_size,vocab_size).to(device)\n        #get input and hidden\n        input_token = trg[0,:]\n        hidden,cell = self.encoder(src)\n        for t in range(1,trg_len):\n            out,hidden,cell = self.decoder(input_token,hidden,cell)\n            outputs[t] = out\n            #decide what passes as input\n            top1 = out.argmax(1)\n            teacher_force = np.random.randn()<teacher_forcing_ratio\n            input_token = trg[t] if teacher_force else top1\n        return outputs","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:18:53.156403Z","iopub.execute_input":"2024-10-29T13:18:53.156786Z","iopub.status.idle":"2024-10-29T13:18:53.166674Z","shell.execute_reply.started":"2024-10-29T13:18:53.156732Z","shell.execute_reply":"2024-10-29T13:18:53.165631Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"input_dim = len(de_vocab)\noutput_dim = len(en_vocab)\nencoder_embedding_dim = 256\ndecoder_embedding_dim = 256\nhidden_size = 512\nnum_layers = 3\nencoder_dropout = 0.5\ndecoder_dropout = 0.5\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nencoder = Encoder(\n    input_dim,\n    encoder_embedding_dim,\n    hidden_size=hidden_size,\n    num_layers=num_layers,\n    dropout=encoder_dropout,\n)\n\ndecoder = Decoder(\n    output_dim,\n    decoder_embedding_dim,\n    hidden_size=hidden_size,\n    num_layers=num_layers,\n    dropout=decoder_dropout,\n)\n\nmodel = Seq2Seq(encoder, decoder, device).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:18:53.167861Z","iopub.execute_input":"2024-10-29T13:18:53.168169Z","iopub.status.idle":"2024-10-29T13:18:53.770494Z","shell.execute_reply.started":"2024-10-29T13:18:53.168139Z","shell.execute_reply":"2024-10-29T13:18:53.769459Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:18:53.771932Z","iopub.execute_input":"2024-10-29T13:18:53.772654Z","iopub.status.idle":"2024-10-29T13:18:53.778942Z","shell.execute_reply.started":"2024-10-29T13:18:53.772601Z","shell.execute_reply":"2024-10-29T13:18:53.778096Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"Seq2Seq(\n  (encoder): Encoder(\n    (dropout): Dropout(p=0.5, inplace=False)\n    (embedding): Embedding(7853, 256)\n    (lstm): LSTM(256, 512, num_layers=3, dropout=0.5, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (dropout): Dropout(p=0.5, inplace=False)\n    (embedding): Embedding(5893, 256)\n    (lstm): LSTM(256, 512, num_layers=3, dropout=0.5, bidirectional=True)\n    (fc): Linear(in_features=1024, out_features=5893, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"def init_weights(m):\n    for name, param in m.named_parameters():\n        nn.init.uniform_(param.data, -0.08, 0.08)\n\n\nmodel.apply(init_weights)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:18:53.780046Z","iopub.execute_input":"2024-10-29T13:18:53.780805Z","iopub.status.idle":"2024-10-29T13:18:53.796034Z","shell.execute_reply.started":"2024-10-29T13:18:53.780751Z","shell.execute_reply":"2024-10-29T13:18:53.795168Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"Seq2Seq(\n  (encoder): Encoder(\n    (dropout): Dropout(p=0.5, inplace=False)\n    (embedding): Embedding(7853, 256)\n    (lstm): LSTM(256, 512, num_layers=3, dropout=0.5, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (dropout): Dropout(p=0.5, inplace=False)\n    (embedding): Embedding(5893, 256)\n    (lstm): LSTM(256, 512, num_layers=3, dropout=0.5, bidirectional=True)\n    (fc): Linear(in_features=1024, out_features=5893, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n\nprint(f\"The model has {count_parameters(model):,} trainable parameters\")","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:18:53.797110Z","iopub.execute_input":"2024-10-29T13:18:53.797400Z","iopub.status.idle":"2024-10-29T13:18:53.803413Z","shell.execute_reply.started":"2024-10-29T13:18:53.797370Z","shell.execute_reply":"2024-10-29T13:18:53.802344Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"The model has 41,065,733 trainable parameters\n","output_type":"stream"}]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters())\ncriterion = nn.CrossEntropyLoss(ignore_index=pad_index)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:18:53.809486Z","iopub.execute_input":"2024-10-29T13:18:53.809776Z","iopub.status.idle":"2024-10-29T13:18:53.814915Z","shell.execute_reply.started":"2024-10-29T13:18:53.809745Z","shell.execute_reply":"2024-10-29T13:18:53.813946Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def train_fn(\n    model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio, device):\n    model.train()\n    epoch_loss = 0\n    for i, batch in enumerate(data_loader):\n        src = batch[\"de_ids\"].to(device)\n        trg = batch[\"en_ids\"].to(device)\n        # src = [src length, batch size]\n        # trg = [trg length, batch size]\n        optimizer.zero_grad()\n        output = model(src, trg, teacher_forcing_ratio)\n        # output = [trg length, batch size, trg vocab size]\n        output_dim = output.shape[-1]\n        output = output[1:].view(-1, output_dim)\n        # output = [(trg length - 1) * batch size, trg vocab size]\n        trg = trg[1:].view(-1)\n        # trg = [(trg length - 1) * batch size]\n        loss = criterion(output, trg)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n        optimizer.step()\n        epoch_loss += loss.item()\n    return epoch_loss / len(data_loader)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:18:53.816374Z","iopub.execute_input":"2024-10-29T13:18:53.816756Z","iopub.status.idle":"2024-10-29T13:18:53.825975Z","shell.execute_reply.started":"2024-10-29T13:18:53.816714Z","shell.execute_reply":"2024-10-29T13:18:53.825006Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def evaluate_fn(model, data_loader, criterion, device):\n    model.eval()\n    epoch_loss = 0\n    with torch.no_grad():\n        for i, batch in enumerate(data_loader):\n            src = batch[\"de_ids\"].to(device)\n            trg = batch[\"en_ids\"].to(device)\n            # src = [src length, batch size]\n            # trg = [trg length, batch size]\n            output = model(src, trg, 0)  # turn off teacher forcing\n            # output = [trg length, batch size, trg vocab size]\n            output_dim = output.shape[-1]\n            output = output[1:].view(-1, output_dim)\n            # output = [(trg length - 1) * batch size, trg vocab size]\n            trg = trg[1:].view(-1)\n            # trg = [(trg length - 1) * batch size]\n            loss = criterion(output, trg)\n            epoch_loss += loss.item()\n    return epoch_loss / len(data_loader)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:18:53.827267Z","iopub.execute_input":"2024-10-29T13:18:53.827663Z","iopub.status.idle":"2024-10-29T13:18:53.835990Z","shell.execute_reply.started":"2024-10-29T13:18:53.827621Z","shell.execute_reply":"2024-10-29T13:18:53.835097Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"n_epochs = 10\nclip = 1.0\nteacher_forcing_ratio = 1\n\nbest_valid_loss = float(\"inf\")\n\nfor epoch in tqdm.tqdm(range(n_epochs)):\n    train_loss = train_fn(\n        model,\n        train_loader,\n        optimizer,\n        criterion,\n        clip,\n        teacher_forcing_ratio,\n        device,\n    )\n    valid_loss = evaluate_fn(\n        model,\n        val_loader,\n        criterion,\n        device,\n    )\n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        torch.save(model.state_dict(), \"tut1-model.pt\")\n    print(f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n    print(f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:18:53.837532Z","iopub.execute_input":"2024-10-29T13:18:53.837917Z","iopub.status.idle":"2024-10-29T13:34:47.364073Z","shell.execute_reply.started":"2024-10-29T13:18:53.837858Z","shell.execute_reply":"2024-10-29T13:34:47.363008Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":" 10%|█         | 1/10 [01:30<13:34, 90.46s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   5.280 | Train PPL: 196.339\n\tValid Loss:   4.820 | Valid PPL: 123.994\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 2/10 [03:05<12:27, 93.39s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   4.601 | Train PPL:  99.597\n\tValid Loss:   4.587 | Valid PPL:  98.223\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 3/10 [04:41<11:01, 94.52s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   3.956 | Train PPL:  52.251\n\tValid Loss:   4.182 | Valid PPL:  65.495\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 4/10 [06:18<09:31, 95.20s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   3.617 | Train PPL:  37.212\n\tValid Loss:   3.816 | Valid PPL:  45.436\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 5/10 [07:53<07:56, 95.35s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   3.390 | Train PPL:  29.664\n\tValid Loss:   3.832 | Valid PPL:  46.164\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 6/10 [09:29<06:22, 95.64s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   3.193 | Train PPL:  24.369\n\tValid Loss:   3.540 | Valid PPL:  34.469\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 7/10 [11:05<04:46, 95.66s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   2.996 | Train PPL:  20.010\n\tValid Loss:   3.446 | Valid PPL:  31.373\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 8/10 [12:41<03:11, 95.69s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   2.856 | Train PPL:  17.383\n\tValid Loss:   3.163 | Valid PPL:  23.652\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [14:17<01:35, 95.77s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   2.680 | Train PPL:  14.578\n\tValid Loss:   3.486 | Valid PPL:  32.658\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [15:53<00:00, 95.35s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   2.543 | Train PPL:  12.720\n\tValid Loss:   3.300 | Valid PPL:  27.107\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"tut1-model.pt\"))\n\ntest_loss = evaluate_fn(model, test_loader, criterion, device)\n\nprint(f\"| Test Loss: {test_loss:.3f} | Test PPL: {np.exp(test_loss):7.3f} |\")","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:34:47.365398Z","iopub.execute_input":"2024-10-29T13:34:47.365720Z","iopub.status.idle":"2024-10-29T13:34:48.758088Z","shell.execute_reply.started":"2024-10-29T13:34:47.365687Z","shell.execute_reply":"2024-10-29T13:34:48.757023Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"| Test Loss: 3.684 | Test PPL:  39.802 |\n","output_type":"stream"}]},{"cell_type":"code","source":"def translate_sentence(\n    sentence,\n    model,\n    en_nlp,\n    de_nlp,\n    en_vocab,\n    de_vocab,\n    lower,\n    sos_token,\n    eos_token,\n    device,\n    max_output_length=25,\n):\n    model.eval()\n    with torch.no_grad():\n        if isinstance(sentence, str):\n            tokens = [token.text for token in de_nlp.tokenizer(sentence)]\n        else:\n            tokens = [token for token in sentence]\n        if lower:\n            tokens = [token.lower() for token in tokens]\n        tokens = [sos_token] + tokens + [eos_token]\n        ids = de_vocab.lookup_indices(tokens)\n        tensor = torch.LongTensor(ids).unsqueeze(-1).to(device)\n        hidden, cell = model.encoder(tensor)\n        inputs = en_vocab.lookup_indices([sos_token])\n        for _ in range(max_output_length):\n            inputs_tensor = torch.LongTensor([inputs[-1]]).to(device)\n            output, hidden, cell = model.decoder(inputs_tensor, hidden, cell)\n            predicted_token = output.argmax(-1).item()\n            inputs.append(predicted_token)\n            if predicted_token == en_vocab[eos_token]:\n                break\n        tokens = en_vocab.lookup_tokens(inputs)\n    return tokens","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:34:48.759288Z","iopub.execute_input":"2024-10-29T13:34:48.759618Z","iopub.status.idle":"2024-10-29T13:34:48.769252Z","shell.execute_reply.started":"2024-10-29T13:34:48.759584Z","shell.execute_reply":"2024-10-29T13:34:48.768391Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"sentence ='Der Mann ist am Weisheitsspross'\nsos_token='<sos>'\neos_token='<eos>'\nlower=True\ntranslation = translate_sentence(\n    sentence,\n    model,\n    en_nlp,\n    de_nlp,\n    en_vocab,\n    de_vocab,\n    lower,\n    sos_token,\n    eos_token,\n    device,\n)\nprint(translation)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T14:04:22.140169Z","iopub.execute_input":"2024-10-29T14:04:22.141119Z","iopub.status.idle":"2024-10-29T14:04:22.157186Z","shell.execute_reply.started":"2024-10-29T14:04:22.141078Z","shell.execute_reply":"2024-10-29T14:04:22.156288Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"['<sos>', 'the', 'woman', 'is', 'looking', 'at', 'the', 'camera', '.', '<eos>']\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data[24766]","metadata":{"execution":{"iopub.status.busy":"2024-10-29T13:44:03.445035Z","iopub.execute_input":"2024-10-29T13:44:03.445443Z","iopub.status.idle":"2024-10-29T13:44:03.454831Z","shell.execute_reply.started":"2024-10-29T13:44:03.445404Z","shell.execute_reply":"2024-10-29T13:44:03.453919Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"{'en_ids': tensor([   2,   48,   30,  150, 3353,   66,   71,  591,  281,    5,    3]),\n 'de_ids': tensor([   2,   43,   30, 4447,   42,  127, 1566,    0,  100,    4,    3]),\n 'en': 'Three men sit contemplating their next bull ride.',\n 'de': 'Drei Männer denken über ihren nächsten Bullenritt nach.',\n 'en_tokens': ['<sos>',\n  'three',\n  'men',\n  'sit',\n  'contemplating',\n  'their',\n  'next',\n  'bull',\n  'ride',\n  '.',\n  '<eos>'],\n 'de_tokens': ['<sos>',\n  'drei',\n  'männer',\n  'denken',\n  'über',\n  'ihren',\n  'nächsten',\n  'bullenritt',\n  'nach',\n  '.',\n  '<eos>']}"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}